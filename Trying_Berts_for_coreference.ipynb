{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trying Berts for coreference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polyankaglade/autoshaving_project_2020/blob/main/Trying_Berts_for_coreference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0xPknceFORt"
      },
      "source": [
        "### От изначального автора тетрадки:\n",
        "\n",
        "This notebook runs the coreferecne resolution model described in [\"SpanBERT: Improving Pre-training by Representing and Predicting Spans\"](https://arxiv.org/pdf/1907.10529.pdf) by Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke Zettlemoyer, Omer Levy, and released here: https://github.com/mandarjoshi90/coref\n",
        "\n",
        "This Colab is by me, Jonathan K. Kummerfeld. My website is www.jkk.name\n",
        "\n",
        "Note:\n",
        "- This code does not handle text with multiple speakers, for that you will need to adjust the data preparation process.\n",
        "- Occasionally I get a bug where either an assertion about the size of the input mask fails or a sequence is being assigned to an array element. It appears to be inconsistent across runs, so I'm not sure what is going on.\n",
        "- The default model is not the best one. I chose it because it is much faster to download.\n",
        "\n",
        "If you have suggestions, please contact me at jkummerf@umich.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWXlf3vQKDo8"
      },
      "source": [
        "# Configuration\n",
        "\n",
        "First, specify your input. If you are just playing with this, edit the provided text. If you want to run on a larger file:\n",
        "\n",
        "1. Upload a file.\n",
        "2. Set the filename."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuvGkbAmI-Ak"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "gd1PiOi1JAzV",
        "outputId": "8a60659e-ffbf-4420-f095-12d912bd0a00"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-validation.tsv', sep='\\t')\r\n",
        "df.head(3)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Pronoun</th>\n",
              "      <th>Pronoun-offset</th>\n",
              "      <th>A</th>\n",
              "      <th>A-offset</th>\n",
              "      <th>A-coref</th>\n",
              "      <th>B</th>\n",
              "      <th>B-offset</th>\n",
              "      <th>B-coref</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>validation-1</td>\n",
              "      <td>He admitted making four trips to China and pla...</td>\n",
              "      <td>him</td>\n",
              "      <td>256</td>\n",
              "      <td>Jose de Venecia Jr</td>\n",
              "      <td>208</td>\n",
              "      <td>False</td>\n",
              "      <td>Abalos</td>\n",
              "      <td>241</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Commission_on_Ele...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>validation-2</td>\n",
              "      <td>Kathleen Nott was born in Camberwell, London. ...</td>\n",
              "      <td>She</td>\n",
              "      <td>185</td>\n",
              "      <td>Ellen</td>\n",
              "      <td>110</td>\n",
              "      <td>False</td>\n",
              "      <td>Kathleen</td>\n",
              "      <td>150</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Kathleen_Nott</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>validation-3</td>\n",
              "      <td>When she returns to her hotel room, a Liberian...</td>\n",
              "      <td>his</td>\n",
              "      <td>435</td>\n",
              "      <td>Jason Scott Lee</td>\n",
              "      <td>383</td>\n",
              "      <td>False</td>\n",
              "      <td>Danny</td>\n",
              "      <td>406</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Hawaii_Five-0_(20...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             ID  ...                                                URL\n",
              "0  validation-1  ...  http://en.wikipedia.org/wiki/Commission_on_Ele...\n",
              "1  validation-2  ...         http://en.wikipedia.org/wiki/Kathleen_Nott\n",
              "2  validation-3  ...  http://en.wikipedia.org/wiki/Hawaii_Five-0_(20...\n",
              "\n",
              "[3 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCxWxLk1JjmH"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTuoGp2AJfmj",
        "outputId": "370291d8-e80d-4556-83f4-485c89ee58a1"
      },
      "source": [
        "Counter([len(t.split('.')) for t in df.Text]).most_common()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(4, 174),\n",
              " (5, 106),\n",
              " (3, 95),\n",
              " (6, 36),\n",
              " (7, 15),\n",
              " (2, 12),\n",
              " (8, 6),\n",
              " (11, 4),\n",
              " (9, 3),\n",
              " (10, 1),\n",
              " (14, 1),\n",
              " (1, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIx_L9cWLLrI",
        "outputId": "404934bb-be20-4d08-e304-75157f9c2971"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "\r\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "CZqQwEI1J0Tx",
        "outputId": "7eab71be-9d58-4f10-911f-0090fe34b215"
      },
      "source": [
        "df['sentences'] = df.Text.apply(sent_tokenize)\r\n",
        "df.head(3)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Pronoun</th>\n",
              "      <th>Pronoun-offset</th>\n",
              "      <th>A</th>\n",
              "      <th>A-offset</th>\n",
              "      <th>A-coref</th>\n",
              "      <th>B</th>\n",
              "      <th>B-offset</th>\n",
              "      <th>B-coref</th>\n",
              "      <th>URL</th>\n",
              "      <th>sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>validation-1</td>\n",
              "      <td>He admitted making four trips to China and pla...</td>\n",
              "      <td>him</td>\n",
              "      <td>256</td>\n",
              "      <td>Jose de Venecia Jr</td>\n",
              "      <td>208</td>\n",
              "      <td>False</td>\n",
              "      <td>Abalos</td>\n",
              "      <td>241</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Commission_on_Ele...</td>\n",
              "      <td>[He admitted making four trips to China and pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>validation-2</td>\n",
              "      <td>Kathleen Nott was born in Camberwell, London. ...</td>\n",
              "      <td>She</td>\n",
              "      <td>185</td>\n",
              "      <td>Ellen</td>\n",
              "      <td>110</td>\n",
              "      <td>False</td>\n",
              "      <td>Kathleen</td>\n",
              "      <td>150</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Kathleen_Nott</td>\n",
              "      <td>[Kathleen Nott was born in Camberwell, London....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>validation-3</td>\n",
              "      <td>When she returns to her hotel room, a Liberian...</td>\n",
              "      <td>his</td>\n",
              "      <td>435</td>\n",
              "      <td>Jason Scott Lee</td>\n",
              "      <td>383</td>\n",
              "      <td>False</td>\n",
              "      <td>Danny</td>\n",
              "      <td>406</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Hawaii_Five-0_(20...</td>\n",
              "      <td>[When she returns to her hotel room, a Liberia...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             ID  ...                                          sentences\n",
              "0  validation-1  ...  [He admitted making four trips to China and pl...\n",
              "1  validation-2  ...  [Kathleen Nott was born in Camberwell, London....\n",
              "2  validation-3  ...  [When she returns to her hotel room, a Liberia...\n",
              "\n",
              "[3 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXgIiCU7Lm0u",
        "outputId": "da70c6a4-a33e-4480-b52a-742b2131f8c0"
      },
      "source": [
        "df['len'] = df['sentences'].apply(len)\r\n",
        "df['len'].value_counts()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3     183\n",
              "4     119\n",
              "2     114\n",
              "5      19\n",
              "1      15\n",
              "10      1\n",
              "9       1\n",
              "8       1\n",
              "7       1\n",
              "Name: len, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v12FXD_hRul4"
      },
      "source": [
        "df.iloc[:100].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmdXWnG9-ni2"
      },
      "source": [
        "Next, specify the data type and model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2l-YNp8KCvh"
      },
      "source": [
        "genre = \"nw\"\n",
        "# The Ontonotes data for training the model contains text from several sources\n",
        "# of very different styles. You need to specify the most suitable one out of:\n",
        "# \"bc\": broadcast conversation\n",
        "# \"bn\": broadcast news\n",
        "# \"mz\": magazine\n",
        "# \"nw\": newswire\n",
        "# \"pt\": Bible text\n",
        "# \"tc\": telephone conversation\n",
        "# \"wb\": web data\n",
        "\n",
        "model_name = \"bert_base\"\n",
        "# The fine-tuned model to use. Options are:\n",
        "# bert_base\n",
        "# spanbert_base\n",
        "# bert_large\n",
        "# spanbert_large"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwu-ICg1QUAS"
      },
      "source": [
        "# System Installation\n",
        "Get the code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlSneeenEwad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2d7298-ca62-451c-a27f-0878cdde3d87"
      },
      "source": [
        "! git clone https://github.com/mandarjoshi90/coref.git\n",
        "%cd coref"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'coref'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 731 (delta 0), reused 0 (delta 0), pack-reused 728\u001b[K\n",
            "Receiving objects: 100% (731/731), 4.17 MiB | 14.29 MiB/s, done.\n",
            "Resolving deltas: 100% (439/439), done.\n",
            "/content/coref\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDVgvzQnMuMG"
      },
      "source": [
        "Temporary hack to fix a requirement (pending pull request)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFety44KE6R_"
      },
      "source": [
        "! cat requirements.txt | sed 's/MarkupSafe==1.0/MarkupSafe==1.1.1/' > tmp\n",
        "! mv tmp requirements.txt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrmR50GZMszn"
      },
      "source": [
        "Set some environment variables. The data directory one is used by the system, the other is so we can use the model defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4cS1Xf0G2EL"
      },
      "source": [
        "import os\n",
        "os.environ['data_dir'] = \".\"\n",
        "os.environ['CHOSEN_MODEL'] = model_name"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1HQYiHqEx1B"
      },
      "source": [
        "Run Setup. Note, some incompatibility issues do appear, but I still find that everything installs and runs. Also, I specifically request tensorflow 2 and then uninstall it to make sure we've got a clean setup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5n-XspBFHjD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c03be402-60ad-4bd8-dd25-84cbe6a98656"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "! pip uninstall -y tensorflow\n",
        "! pip install -r requirements.txt --log install-log.txt -q\n",
        "! ./setup_all.sh"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.4.0:\n",
            "  Successfully uninstalled tensorflow-2.4.0\n",
            "\u001b[K     |████████████████████████████████| 102kB 4.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 14.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 22.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6MB 944kB/s \n",
            "\u001b[K     |████████████████████████████████| 552kB 49.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2MB 48.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.4MB 25.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 47.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 45.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 49.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 10.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.4MB 1.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.1MB 51.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 46.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.7MB 46.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 53.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 51.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 512kB 46.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 12.4MB 38.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 50.0MB 165kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 41.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 491kB 43.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 377.0MB 46kB/s \n",
            "\u001b[K     |████████████████████████████████| 748.9MB 21kB/s \n",
            "\u001b[K     |████████████████████████████████| 8.8MB 45.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 327kB 53.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.1MB 39.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 53.8MB/s \n",
            "\u001b[?25h  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for JPype1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mmh3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for msgpack-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pycparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyhocon (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-metadata 0.26.0 has requirement absl-py<0.11,>=0.9, but you'll have absl-py 0.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyasn1-modules 0.2.8 has requirement pyasn1<0.5.0,>=0.4.6, but you'll have pyasn1 0.4.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pandas 1.1.5 has requirement python-dateutil>=2.7.3, but you'll have python-dateutil 2.6.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: nbclient 0.5.1 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement astor~=0.8.1, but you'll have astor 0.8.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: flask 1.1.2 has requirement Jinja2>=2.10.1, but you'll have jinja2 2.10 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: flask 1.1.2 has requirement Werkzeug>=0.15, but you'll have werkzeug 0.14.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement python-dateutil>=2.8.0, but you'll have python-dateutil 2.6.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.31 has requirement scipy>=1.1.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knVqV4uHMyc3"
      },
      "source": [
        "Get the finetuned BERT model specified above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNETVn_RMxVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c31daa-f3a8-4641-8ec5-f907cdce5fe2"
      },
      "source": [
        "! ./download_pretrained.sh $CHOSEN_MODEL"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading bert_base\n",
            "--2020-12-22 20:27:12--  http://nlp.cs.washington.edu/pair2vec/bert_base.tar.gz\n",
            "Resolving nlp.cs.washington.edu (nlp.cs.washington.edu)... 128.208.3.120, 2607:4000:200:12::78\n",
            "Connecting to nlp.cs.washington.edu (nlp.cs.washington.edu)|128.208.3.120|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1593421271 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘./bert_base.tar.gz’\n",
            "\n",
            "bert_base.tar.gz    100%[===================>]   1.48G  70.5MB/s    in 22s     \n",
            "\n",
            "2020-12-22 20:27:34 (69.0 MB/s) - ‘./bert_base.tar.gz’ saved [1593421271/1593421271]\n",
            "\n",
            "bert_base/\n",
            "bert_base/checkpoint\n",
            "bert_base/events.out.tfevents.1551148826.learnfair0213\n",
            "bert_base/events.out.tfevents.1551148825.learnfair0213\n",
            "bert_base/model.max.ckpt.index\n",
            "bert_base/stdout.log\n",
            "bert_base/bert_config.json\n",
            "bert_base/vocab.txt\n",
            "bert_base/model.max.ckpt.data-00000-of-00001\n",
            "bert_base/events.out.tfevents.1551148806.learnfair2008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EucqOJQ6QZuG"
      },
      "source": [
        "# Data Preparation and Prediction\n",
        "\n",
        "Process the data to be in the required input format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0jLV2_sHC7e"
      },
      "source": [
        "from bert import tokenization\n",
        "import json\n",
        "\n",
        "def make_line(text):\n",
        "    data = {\n",
        "        'doc_key': genre,\n",
        "        'sentences': [[\"[CLS]\"]],\n",
        "        'speakers': [[\"[SPL]\"]],\n",
        "        'clusters': [],\n",
        "        'sentence_map': [0],\n",
        "        'subtoken_map': [0],\n",
        "    }\n",
        "\n",
        "    # Determine Max Segment\n",
        "    max_segment = None\n",
        "    for line in open('experiments.conf'):\n",
        "        if line.startswith(model_name):\n",
        "            max_segment = True\n",
        "        elif line.strip().startswith(\"max_segment_len\"):\n",
        "            if max_segment:\n",
        "                max_segment = int(line.strip().split()[-1])\n",
        "                break\n",
        "\n",
        "    tokenizer = tokenization.FullTokenizer(vocab_file=\"cased_config_vocab/vocab.txt\", do_lower_case=False)\n",
        "    subtoken_num = 0\n",
        "    for sent_num, line in enumerate(text):\n",
        "        raw_tokens = line.split()\n",
        "        tokens = tokenizer.tokenize(line)\n",
        "        if len(tokens) + len(data['sentences'][-1]) >= max_segment:\n",
        "            data['sentences'][-1].append(\"[SEP]\")\n",
        "            data['sentences'].append([\"[CLS]\"])\n",
        "            data['speakers'][-1].append(\"[SPL]\")\n",
        "            data['speakers'].append([\"[SPL]\"])\n",
        "            data['sentence_map'].append(sent_num - 1)\n",
        "            data['subtoken_map'].append(subtoken_num - 1)\n",
        "            data['sentence_map'].append(sent_num)\n",
        "            data['subtoken_map'].append(subtoken_num)\n",
        "\n",
        "        ctoken = raw_tokens[0]\n",
        "        cpos = 0\n",
        "        for token in tokens:\n",
        "            data['sentences'][-1].append(token)\n",
        "            data['speakers'][-1].append(\"-\")\n",
        "            data['sentence_map'].append(sent_num)\n",
        "            data['subtoken_map'].append(subtoken_num)\n",
        "            \n",
        "            if token.startswith(\"##\"):\n",
        "                token = token[2:]\n",
        "            if len(ctoken) == len(token):\n",
        "                subtoken_num += 1\n",
        "                cpos += 1\n",
        "                if cpos < len(raw_tokens):\n",
        "                    ctoken = raw_tokens[cpos]\n",
        "            else:\n",
        "                ctoken = ctoken[len(token):]\n",
        "\n",
        "    data['sentences'][-1].append(\"[SEP]\")\n",
        "    data['speakers'][-1].append(\"[SPL]\")\n",
        "    data['sentence_map'].append(sent_num - 1)\n",
        "    data['subtoken_map'].append(subtoken_num - 1)\n",
        "\n",
        "    return data"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ilio_obNchl"
      },
      "source": [
        "test_data = [make_line(t) for t in df.sentences[:100]]"
      ],
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDtwHzljYyi9",
        "outputId": "2ec02d18-8ee7-4d7a-810a-c6d812a6f71f"
      },
      "source": [
        "print(test_data[0]['sentences'][0])"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'He', 'admitted', 'making', 'four', 'trips', 'to', 'China', 'and', 'playing', 'golf', 'there', '.', 'He', 'also', 'admitted', 'that', 'Z', '##TE', 'officials', ',', 'whom', 'he', 'says', 'are', 'his', 'golf', 'b', '##udd', '##ies', ',', 'hosted', 'and', 'paid', 'for', 'the', 'trips', '.', 'Jose', 'de', 'V', '##ene', '##cia', 'III', ',', 'son', 'of', 'House', 'Speaker', 'Jose', 'de', 'V', '##ene', '##cia', 'Jr', ',', 'alleged', 'that', 'A', '##bal', '##os', 'offered', 'him', 'US', '$', '10', 'million', 'to', 'withdraw', 'his', 'proposal', 'on', 'the', 'N', '##B', '##N', 'project', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9Gp-5tXMZfG"
      },
      "source": [
        "with open(\"test.in.json\", 'w') as out:\r\n",
        "    for d in test_data:\r\n",
        "        json.dump(d, out, sort_keys=True)\r\n",
        "        out.write('\\n')\r\n",
        "\r\n",
        "#! cat test.in.json"
      ],
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM3yxYqiz-8m"
      },
      "source": [
        "Run Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K_Z0h-LS8od",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0e901f-8136-4c5b-8859-7ca49b52e2dd"
      },
      "source": [
        "! GPU=0 python predict.py $CHOSEN_MODEL test.in.json test2.out.txt"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W1222 20:30:43.574110 139691296565120 deprecation_wrapper.py:119] From /content/coref/coref_ops.py:11: The name tf.NotDifferentiable is deprecated. Please use tf.no_gradient instead.\n",
            "\n",
            "W1222 20:30:43.599173 139691296565120 deprecation_wrapper.py:119] From /content/coref/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W1222 20:30:44.956030 139691296565120 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Setting CUDA_VISIBLE_DEVICES to: 0\n",
            "Running experiment: bert_base\n",
            "data_dir = \"/sdb/data/new_coref\"\n",
            "model_type = \"independent\"\n",
            "max_top_antecedents = 50\n",
            "max_training_sentences = 11\n",
            "top_span_ratio = 0.4\n",
            "max_num_speakers = 20\n",
            "max_segment_len = 128\n",
            "bert_learning_rate = 1e-05\n",
            "task_learning_rate = 0.0002\n",
            "num_docs = 2802\n",
            "dropout_rate = 0.3\n",
            "ffnn_size = 3000\n",
            "ffnn_depth = 1\n",
            "num_epochs = 20\n",
            "feature_size = 20\n",
            "max_span_width = 30\n",
            "use_metadata = true\n",
            "use_features = true\n",
            "use_segment_distance = true\n",
            "model_heads = true\n",
            "coref_depth = 2\n",
            "coarse_to_fine = true\n",
            "fine_grained = true\n",
            "use_prior = true\n",
            "train_path = \"./train.english.128.jsonlines\"\n",
            "eval_path = \"./dev.english.128.jsonlines\"\n",
            "conll_eval_path = \"./dev.english.v4_gold_conll\"\n",
            "single_example = true\n",
            "genres = [\n",
            "  \"bc\"\n",
            "  \"bn\"\n",
            "  \"mz\"\n",
            "  \"nw\"\n",
            "  \"pt\"\n",
            "  \"tc\"\n",
            "  \"wb\"\n",
            "]\n",
            "eval_frequency = 1000\n",
            "report_frequency = 100\n",
            "log_root = \".\"\n",
            "adam_eps = 1e-06\n",
            "task_optimizer = \"adam\"\n",
            "bert_config_file = \"./bert_base/bert_config.json\"\n",
            "vocab_file = \"./bert_base/vocab.txt\"\n",
            "tf_checkpoint = \"./bert_base/model.max.ckpt\"\n",
            "init_checkpoint = \"./bert_base/model.max.ckpt\"\n",
            "log_dir = \"./bert_base\"\n",
            "W1222 20:30:45.028734 139691296565120 deprecation_wrapper.py:119] From /content/coref/bert/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1222 20:30:45.114146 139691296565120 deprecation_wrapper.py:119] From /content/coref/independent.py:48: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W1222 20:30:45.122800 139691296565120 deprecation_wrapper.py:119] From /content/coref/independent.py:50: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n",
            "\n",
            "W1222 20:30:45.126783 139691296565120 deprecation.py:323] From /content/coref/bert/modeling.py:158: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1222 20:30:45.142550 139691296565120 deprecation_wrapper.py:119] From /content/coref/bert/modeling.py:175: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W1222 20:30:45.142787 139691296565120 deprecation_wrapper.py:119] From /content/coref/bert/modeling.py:175: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W1222 20:30:45.217837 139691296565120 deprecation.py:506] From /content/coref/bert/modeling.py:362: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W1222 20:30:45.264913 139691296565120 deprecation.py:323] From /content/coref/bert/modeling.py:676: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W1222 20:30:48.188479 139691296565120 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1222 20:30:48.270787 139691296565120 deprecation.py:323] From /content/coref/independent.py:221: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1222 20:30:48.321802 139691296565120 deprecation_wrapper.py:119] From /content/coref/util.py:117: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.\n",
            "\n",
            "W1222 20:30:48.917917 139691296565120 deprecation_wrapper.py:119] From /content/coref/independent.py:60: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "**** Trainable Variables ****\n",
            "  name = bert/embeddings/word_embeddings:0, shape = (28996, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "  name = span_width_embeddings:0, shape = (30, 20), *INIT_FROM_CKPT*\n",
            "  name = mention_word_attn/output_weights:0, shape = (768, 1), *INIT_FROM_CKPT*\n",
            "  name = mention_word_attn/output_bias:0, shape = (1,), *INIT_FROM_CKPT*\n",
            "  name = mention_scores/hidden_weights_0:0, shape = (2324, 3000), *INIT_FROM_CKPT*\n",
            "  name = mention_scores/hidden_bias_0:0, shape = (3000,), *INIT_FROM_CKPT*\n",
            "  name = mention_scores/output_weights:0, shape = (3000, 1), *INIT_FROM_CKPT*\n",
            "  name = mention_scores/output_bias:0, shape = (1,), *INIT_FROM_CKPT*\n",
            "  name = span_width_prior_embeddings:0, shape = (30, 20), *INIT_FROM_CKPT*\n",
            "  name = width_scores/hidden_weights_0:0, shape = (20, 3000), *INIT_FROM_CKPT*\n",
            "  name = width_scores/hidden_bias_0:0, shape = (3000,), *INIT_FROM_CKPT*\n",
            "  name = width_scores/output_weights:0, shape = (3000, 1), *INIT_FROM_CKPT*\n",
            "  name = width_scores/output_bias:0, shape = (1,), *INIT_FROM_CKPT*\n",
            "  name = genre_embeddings:0, shape = (7, 20), *INIT_FROM_CKPT*\n",
            "  name = src_projection/output_weights:0, shape = (2324, 2324), *INIT_FROM_CKPT*\n",
            "  name = src_projection/output_bias:0, shape = (2324,), *INIT_FROM_CKPT*\n",
            "  name = antecedent_distance_emb:0, shape = (10, 20), *INIT_FROM_CKPT*\n",
            "  name = output_weights:0, shape = (20, 1), *INIT_FROM_CKPT*\n",
            "  name = output_bias:0, shape = (1,), *INIT_FROM_CKPT*\n",
            "  name = coref_layer/same_speaker_emb:0, shape = (2, 20), *INIT_FROM_CKPT*\n",
            "  name = coref_layer/antecedent_distance_emb:0, shape = (10, 20), *INIT_FROM_CKPT*\n",
            "  name = coref_layer/segment_distance/segment_distance_embeddings:0, shape = (11, 20), *INIT_FROM_CKPT*\n",
            "  name = coref_layer/slow_antecedent_scores/hidden_weights_0:0, shape = (7052, 3000), *INIT_FROM_CKPT*\n",
            "  name = coref_layer/slow_antecedent_scores/hidden_bias_0:0, shape = (3000,), *INIT_FROM_CKPT*\n",
            "  name = coref_layer/slow_antecedent_scores/output_weights:0, shape = (3000, 1), *INIT_FROM_CKPT*\n",
            "  name = coref_layer/slow_antecedent_scores/output_bias:0, shape = (1,), *INIT_FROM_CKPT*\n",
            "  name = coref_layer/f/output_weights:0, shape = (4648, 2324), *INIT_FROM_CKPT*\n",
            "  name = coref_layer/f/output_bias:0, shape = (2324,), *INIT_FROM_CKPT*\n",
            "W1222 20:30:49.779867 139691296565120 deprecation_wrapper.py:119] From /content/coref/independent.py:74: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W1222 20:30:49.786209 139691296565120 deprecation_wrapper.py:119] From /content/coref/optimization.py:13: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W1222 20:30:49.790352 139691296565120 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W1222 20:30:49.811128 139691296565120 deprecation_wrapper.py:119] From /content/coref/optimization.py:64: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "bert:task 199 27\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "2020-12-22 20:31:00.386788: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2020-12-22 20:31:00.397657: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-12-22 20:31:00.397792: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (adf27bb263e2): /proc/driver/nvidia/version does not exist\n",
            "2020-12-22 20:31:00.398487: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-12-22 20:31:00.407784: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-12-22 20:31:00.408261: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a919c0 executing computations on platform Host. Devices:\n",
            "2020-12-22 20:31:00.408308: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "Restoring from ./bert_base/model.max.ckpt\n",
            "2020-12-22 20:31:05.993453: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "W1222 20:31:13.949413 139691296565120 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Decoded 1 examples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9slRLDdQFDP"
      },
      "source": [
        "# Output Handling\n",
        "\n",
        "Finally, we do a little processing to get the output to have the same token indices as our input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMiNJOgSUA7D"
      },
      "source": [
        "def convert_mention(output, mention, comb_text):\n",
        "    start = output['subtoken_map'][mention[0]]\n",
        "    end = output['subtoken_map'][mention[1]] + 1\n",
        "    nmention = (start, end)\n",
        "    mtext = ''.join(' '.join(comb_text[mention[0]:mention[1]+1]).split(\" ##\"))\n",
        "    return (nmention, mtext)\n",
        "\n",
        "def get_clusters(output):\n",
        "    comb_text = [word for sentence in output['sentences'] for word in sentence]\n",
        "    seen = set()\n",
        "    #print('Clusters:')\n",
        "    clusters = []\n",
        "    for cluster in output['predicted_clusters']:\n",
        "        mapped = []\n",
        "        for mention in cluster:\n",
        "            seen.add(tuple(mention))\n",
        "            mapped.append(convert_mention(output, mention, comb_text))\n",
        "        clusters.append(mapped)\n",
        "\n",
        "    return clusters\n",
        "\n",
        "# print('\\nMentions:')\n",
        "# for mention in output['top_spans']:\n",
        "#     if tuple(mention) in seen:\n",
        "#         continue\n",
        "#     print(convert_mention(mention), end=\",\\n\")"
      ],
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00aHmiU7QH9e"
      },
      "source": [
        "with open('test2.out.txt') as f:\r\n",
        "    lines = f.readlines()"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL3mkadKQSLk"
      },
      "source": [
        "outputs = [json.loads(l) for l in lines]"
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kFAMI1tX-t0",
        "outputId": "ac86928e-8e28-47f2-9577-020807127aff"
      },
      "source": [
        "print(outputs[0]['sentences'])"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['[CLS]', 'He', 'admitted', 'making', 'four', 'trips', 'to', 'China', 'and', 'playing', 'golf', 'there', '.', 'He', 'also', 'admitted', 'that', 'Z', '##TE', 'officials', ',', 'whom', 'he', 'says', 'are', 'his', 'golf', 'b', '##udd', '##ies', ',', 'hosted', 'and', 'paid', 'for', 'the', 'trips', '.', 'Jose', 'de', 'V', '##ene', '##cia', 'III', ',', 'son', 'of', 'House', 'Speaker', 'Jose', 'de', 'V', '##ene', '##cia', 'Jr', ',', 'alleged', 'that', 'A', '##bal', '##os', 'offered', 'him', 'US', '$', '10', 'million', 'to', 'withdraw', 'his', 'proposal', 'on', 'the', 'N', '##B', '##N', 'project', '.', '[SEP]']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI7bAE5vIZVG"
      },
      "source": [
        "predictions = [get_clusters(output) for output in outputs]"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EaHW0lYYF6_",
        "outputId": "81cc2b4c-052f-4c16-c2c2-1f2292aefc54"
      },
      "source": [
        "clusters = [[[m[1] for m in cluster] for cluster in clusters] for clusters in predictions]\r\n",
        "clusters[1]"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Kathleen Nott', 'Her', 'her', 'Kathleen', 'She'],\n",
              " ['London', 'London', 'London']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xizU14IkhvXX"
      },
      "source": [
        "test_df = df.iloc[:100].copy()"
      ],
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y4lhHLeYITJ"
      },
      "source": [
        "test_df['clusters'] = clusters"
      ],
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxJDIqtkLMlg"
      },
      "source": [
        "# Сравнение (лучше см. [тетрадку](https://github.com/polyankaglade/autoshaving_project_2020/blob/main/Compare%20predictions%20to%20GAP.ipynb))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsu9FlVn1HI-"
      },
      "source": [
        "def flatten(cluster):\r\n",
        "    clus_words = []\r\n",
        "    for ent in cluster:\r\n",
        "        clus_words.extend(ent.split())\r\n",
        "    return ' '.join(clus_words)"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM48eTrD7tch",
        "outputId": "7d4bfc83-c648-43d8-f50e-5092d3f88478"
      },
      "source": [
        "test_df.clusters[1]"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Kathleen Nott', 'Her', 'her', 'Kathleen', 'She'],\n",
              " ['London', 'London', 'London']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e502bIH41NGa",
        "outputId": "ee5a0f38-4948-49d8-ab48-16b3b296548f"
      },
      "source": [
        "flatten(test_df.clusters[1][0])"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Kathleen Nott Her her Kathleen She'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVDe649nZqae"
      },
      "source": [
        "def compare(pronoun, a, a_value, b, b_value, clusters):\r\n",
        "\r\n",
        "    #clusters = [flatten(c) for c in clusters]\r\n",
        "\r\n",
        "    positives = []\r\n",
        "    negatives = []\r\n",
        "    if a_value:\r\n",
        "        positives.append([pronoun, a])\r\n",
        "    else:\r\n",
        "        negatives.append([pronoun, a])\r\n",
        "\r\n",
        "    if b_value:\r\n",
        "        positives.append([pronoun, b])\r\n",
        "    else:\r\n",
        "        negatives.append([pronoun, b])\r\n",
        "\r\n",
        "    \r\n",
        "    tp_clusters = []\r\n",
        "    tp_gold = []\r\n",
        "\r\n",
        "    fp_clusters = []\r\n",
        "    fp_gold = []\r\n",
        "\r\n",
        "    tn_clusters = []\r\n",
        "    fn_clusters = []\r\n",
        "\r\n",
        "    # for cluster in clusters:\r\n",
        "\r\n",
        "    #     for p in positives:\r\n",
        "    #         if p[0] and p[1] in cluster:\r\n",
        "    #             tp_clusters.append(cluster)\r\n",
        "    #     for n in negatives:\r\n",
        "    #         if n[0] and n[1] in cluster:\r\n",
        "    #             fp_clusters.append(cluster)\r\n",
        "\r\n",
        "    for p in positives:\r\n",
        "        for cluster in clusters:\r\n",
        "            if p[0] in cluster and p[1] in cluster:\r\n",
        "                tp_clusters.append(cluster)\r\n",
        "                tp_gold.append(p)\r\n",
        "\r\n",
        "    for p in positives:\r\n",
        "        if p not in tp_gold:\r\n",
        "            fn_clusters.append(p)\r\n",
        "\r\n",
        "    for n in negatives:\r\n",
        "        for cluster in clusters:\r\n",
        "            if n[0] in cluster and n[1] in cluster:\r\n",
        "                fp_clusters.append(cluster)\r\n",
        "                fp_gold.append(n)\r\n",
        "\r\n",
        "    for n in negatives:\r\n",
        "        if n not in fp_gold:\r\n",
        "            tn_clusters.append(n)\r\n",
        "\r\n",
        "    return tp_clusters, fp_clusters, tn_clusters, fn_clusters"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s55K-0Osgr9w"
      },
      "source": [
        "res = test_df.apply(lambda x: compare(x['Pronoun'], x['A'], x['A-coref'], x['B'], x['B-coref'], x['clusters']), axis=1).values"
      ],
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7Tzo1faxwhX"
      },
      "source": [
        "def clusters_to_string(clusters):\r\n",
        "    return '; '.join([', '.join([m for m in c]) for c in clusters])"
      ],
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8GR5Ik2kBIG"
      },
      "source": [
        "for i, n in enumerate(['tp', 'fp', 'tn', 'fn']):\r\n",
        "\r\n",
        "    test_df[n] = [r[i] for r in res]\r\n",
        "    test_df[f'{n}_count'] = test_df[n].apply(len)\r\n",
        "    test_df[f'str_{n}'] = test_df[n].apply(clusters_to_string)"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR5LNKYBynRC"
      },
      "source": [
        "test_df['str_clusters'] = test_df.clusters.apply(clusters_to_string)"
      ],
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "M_OjTfgakwdE",
        "outputId": "175db6cf-97d0-4a52-d79f-1a7b92a21262"
      },
      "source": [
        "test_df[['Pronoun', 'A', 'A-coref', 'B', 'B-coref', 'tp_count', 'fp_count', 'tn_count', 'fn_count']]"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pronoun</th>\n",
              "      <th>A</th>\n",
              "      <th>A-coref</th>\n",
              "      <th>B</th>\n",
              "      <th>B-coref</th>\n",
              "      <th>tp_count</th>\n",
              "      <th>fp_count</th>\n",
              "      <th>tn_count</th>\n",
              "      <th>fn_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>him</td>\n",
              "      <td>Jose de Venecia Jr</td>\n",
              "      <td>False</td>\n",
              "      <td>Abalos</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>She</td>\n",
              "      <td>Ellen</td>\n",
              "      <td>False</td>\n",
              "      <td>Kathleen</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>his</td>\n",
              "      <td>Jason Scott Lee</td>\n",
              "      <td>False</td>\n",
              "      <td>Danny</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>he</td>\n",
              "      <td>Reucassel</td>\n",
              "      <td>True</td>\n",
              "      <td>Debnam</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>she</td>\n",
              "      <td>Finch Hatton</td>\n",
              "      <td>False</td>\n",
              "      <td>Beryl Markham</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>he</td>\n",
              "      <td>Fred Ziffel</td>\n",
              "      <td>False</td>\n",
              "      <td>Drucker</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>her</td>\n",
              "      <td>Seema</td>\n",
              "      <td>False</td>\n",
              "      <td>Shalini</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>she</td>\n",
              "      <td>Branton</td>\n",
              "      <td>False</td>\n",
              "      <td>Heloise</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>his</td>\n",
              "      <td>Hibbert</td>\n",
              "      <td>True</td>\n",
              "      <td>Christopher Robin</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>his</td>\n",
              "      <td>Charlie Feathers</td>\n",
              "      <td>False</td>\n",
              "      <td>Billy Hancock</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pronoun                   A  A-coref  ... fp_count  tn_count  fn_count\n",
              "0      him  Jose de Venecia Jr    False  ...        0         2         0\n",
              "1      She               Ellen    False  ...        0         1         0\n",
              "2      his     Jason Scott Lee    False  ...        0         1         0\n",
              "3       he           Reucassel     True  ...        0         1         0\n",
              "4      she        Finch Hatton    False  ...        0         1         1\n",
              "..     ...                 ...      ...  ...      ...       ...       ...\n",
              "95      he         Fred Ziffel    False  ...        0         1         0\n",
              "96     her               Seema    False  ...        2         0         0\n",
              "97     she             Branton    False  ...        0         2         0\n",
              "98     his             Hibbert     True  ...        0         1         0\n",
              "99     his    Charlie Feathers    False  ...        0         1         1\n",
              "\n",
              "[100 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKqXeSW3lo_F",
        "outputId": "ddd9f871-7f67-4aa2-d24b-9f4ef6ab19b8"
      },
      "source": [
        "len(test_df[test_df['fp_count'] + test_df['fn_count'] > 0])"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6ZkLZz2mCo1",
        "outputId": "c3372ed9-113e-4992-ec1d-afd4ecf4ce39"
      },
      "source": [
        "len(test_df[test_df['tp_count'] + test_df['tn_count'] == 2])"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5w7EpEIhszdS",
        "outputId": "72fa9f67-a387-4928-98a5-71cc9cbc34a3"
      },
      "source": [
        "falses = test_df[test_df['fp_count'] + test_df['fn_count'] > 0]\r\n",
        "falses[['Pronoun', 'A', 'A-coref', 'B', 'B-coref', 'str_clusters', 'str_fp', 'str_fn', 'str_tp', 'str_tn']]"
      ],
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pronoun</th>\n",
              "      <th>A</th>\n",
              "      <th>A-coref</th>\n",
              "      <th>B</th>\n",
              "      <th>B-coref</th>\n",
              "      <th>str_clusters</th>\n",
              "      <th>str_fp</th>\n",
              "      <th>str_fn</th>\n",
              "      <th>str_tp</th>\n",
              "      <th>str_tn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>she</td>\n",
              "      <td>Finch Hatton</td>\n",
              "      <td>False</td>\n",
              "      <td>Beryl Markham</td>\n",
              "      <td>True</td>\n",
              "      <td>Karen Blixen, her, her; her husband, Finch Hat...</td>\n",
              "      <td></td>\n",
              "      <td>she, Beryl Markham</td>\n",
              "      <td></td>\n",
              "      <td>she, Finch Hatton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>he</td>\n",
              "      <td>James Randi</td>\n",
              "      <td>False</td>\n",
              "      <td>Jos* Alvarez</td>\n",
              "      <td>True</td>\n",
              "      <td>stage performer Jos * Alvarez, he</td>\n",
              "      <td></td>\n",
              "      <td>he, Jos* Alvarez</td>\n",
              "      <td></td>\n",
              "      <td>he, James Randi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>his</td>\n",
              "      <td>Colin</td>\n",
              "      <td>False</td>\n",
              "      <td>Jake Burns</td>\n",
              "      <td>True</td>\n",
              "      <td>He, He, he, Colin; the Belfast Sunday News, th...</td>\n",
              "      <td></td>\n",
              "      <td>his, Jake Burns</td>\n",
              "      <td></td>\n",
              "      <td>his, Colin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>he</td>\n",
              "      <td>Scott</td>\n",
              "      <td>False</td>\n",
              "      <td>Cowan</td>\n",
              "      <td>True</td>\n",
              "      <td>F . Scott Fitzgerald ' s, Fitzgerald, his, Sco...</td>\n",
              "      <td>F . Scott Fitzgerald ' s, Fitzgerald, his, Sco...</td>\n",
              "      <td>he, Cowan</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>her</td>\n",
              "      <td>Beverley Callard</td>\n",
              "      <td>True</td>\n",
              "      <td>Liz</td>\n",
              "      <td>False</td>\n",
              "      <td>her, Liz, her, Beverley Callard, Liz</td>\n",
              "      <td>her, Liz, her, Beverley Callard, Liz</td>\n",
              "      <td></td>\n",
              "      <td>her, Liz, her, Beverley Callard, Liz</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>he</td>\n",
              "      <td>Ioannis Mamouris</td>\n",
              "      <td>False</td>\n",
              "      <td>Kallergis</td>\n",
              "      <td>True</td>\n",
              "      <td>This particular government, Greece, Greece; th...</td>\n",
              "      <td></td>\n",
              "      <td>he, Kallergis</td>\n",
              "      <td></td>\n",
              "      <td>he, Ioannis Mamouris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>her</td>\n",
              "      <td>Queen</td>\n",
              "      <td>True</td>\n",
              "      <td>Crystal</td>\n",
              "      <td>False</td>\n",
              "      <td>Princess Luminous, her, her, Princess Luminous...</td>\n",
              "      <td></td>\n",
              "      <td>her, Queen</td>\n",
              "      <td></td>\n",
              "      <td>her, Crystal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>his</td>\n",
              "      <td>Dan Dailey</td>\n",
              "      <td>False</td>\n",
              "      <td>Michael Kidd</td>\n",
              "      <td>True</td>\n",
              "      <td>dancer / choreographer Michael Kidd, his</td>\n",
              "      <td></td>\n",
              "      <td>his, Michael Kidd</td>\n",
              "      <td></td>\n",
              "      <td>his, Dan Dailey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>his</td>\n",
              "      <td>Dwight</td>\n",
              "      <td>False</td>\n",
              "      <td>Andy</td>\n",
              "      <td>True</td>\n",
              "      <td>Andy, Dwight ' s, Dwight ' s, Dwight, Andy, th...</td>\n",
              "      <td>Andy, Dwight ' s, Dwight ' s, Dwight, Andy, th...</td>\n",
              "      <td></td>\n",
              "      <td>Andy, Dwight ' s, Dwight ' s, Dwight, Andy, th...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>his</td>\n",
              "      <td>Morris</td>\n",
              "      <td>False</td>\n",
              "      <td>David W. Taylor</td>\n",
              "      <td>True</td>\n",
              "      <td>Rear Admiral David W . Taylor, his</td>\n",
              "      <td></td>\n",
              "      <td>his, David W. Taylor</td>\n",
              "      <td></td>\n",
              "      <td>his, Morris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>his</td>\n",
              "      <td>Joe Brown</td>\n",
              "      <td>False</td>\n",
              "      <td>Joe Christmas</td>\n",
              "      <td>True</td>\n",
              "      <td>Byron, his, him, his; Lucas Burch / Joe Brown ...</td>\n",
              "      <td></td>\n",
              "      <td>his, Joe Christmas</td>\n",
              "      <td></td>\n",
              "      <td>his, Joe Brown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>his</td>\n",
              "      <td>Martin O*Malley</td>\n",
              "      <td>True</td>\n",
              "      <td>Adkins</td>\n",
              "      <td>False</td>\n",
              "      <td>General Adkins, He, General Adkins; Governor M...</td>\n",
              "      <td></td>\n",
              "      <td>his, Martin O*Malley</td>\n",
              "      <td></td>\n",
              "      <td>his, Adkins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>his</td>\n",
              "      <td>Mughal</td>\n",
              "      <td>False</td>\n",
              "      <td>Shahjahan</td>\n",
              "      <td>True</td>\n",
              "      <td>Ahmedabad, Ahmedabad, the city; the Mughal rei...</td>\n",
              "      <td></td>\n",
              "      <td>his, Shahjahan</td>\n",
              "      <td></td>\n",
              "      <td>his, Mughal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>him</td>\n",
              "      <td>Saul</td>\n",
              "      <td>False</td>\n",
              "      <td>Haqqani</td>\n",
              "      <td>True</td>\n",
              "      <td>Quinn, his, him, Quinn; Haqqani, Haqqani ' s, ...</td>\n",
              "      <td>Saul, him</td>\n",
              "      <td>him, Haqqani</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>He</td>\n",
              "      <td>Thomas Coats</td>\n",
              "      <td>True</td>\n",
              "      <td>Baronet</td>\n",
              "      <td>False</td>\n",
              "      <td>Sir Thomas Coats Glen Glen - Coats , 2nd Baron...</td>\n",
              "      <td></td>\n",
              "      <td>He, Thomas Coats</td>\n",
              "      <td></td>\n",
              "      <td>He, Baronet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>his</td>\n",
              "      <td>Clarence Doust</td>\n",
              "      <td>True</td>\n",
              "      <td>Nelson</td>\n",
              "      <td>False</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>his, Clarence Doust</td>\n",
              "      <td></td>\n",
              "      <td>his, Nelson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>He</td>\n",
              "      <td>Bawa Ardalan</td>\n",
              "      <td>True</td>\n",
              "      <td>Ahmad bin Marwan</td>\n",
              "      <td>False</td>\n",
              "      <td>people from Ardalan tribe, themselves; Sinne (...</td>\n",
              "      <td></td>\n",
              "      <td>He, Bawa Ardalan</td>\n",
              "      <td></td>\n",
              "      <td>He, Ahmad bin Marwan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>he</td>\n",
              "      <td>Daniel Sims</td>\n",
              "      <td>False</td>\n",
              "      <td>Hamza Aziz</td>\n",
              "      <td>True</td>\n",
              "      <td>* kamiden ' s cel - shaded visuals, they; it, ...</td>\n",
              "      <td></td>\n",
              "      <td>he, Hamza Aziz</td>\n",
              "      <td></td>\n",
              "      <td>he, Daniel Sims</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>his</td>\n",
              "      <td>Kelder</td>\n",
              "      <td>True</td>\n",
              "      <td>Lobsang Rampa</td>\n",
              "      <td>False</td>\n",
              "      <td>The ` ` Tibetans ' ', The practice; Christophe...</td>\n",
              "      <td></td>\n",
              "      <td>his, Kelder</td>\n",
              "      <td></td>\n",
              "      <td>his, Lobsang Rampa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>his</td>\n",
              "      <td>Charles</td>\n",
              "      <td>False</td>\n",
              "      <td>Paul</td>\n",
              "      <td>True</td>\n",
              "      <td>It, it, it; Charles, Paul, his, his</td>\n",
              "      <td>Charles, Paul, his, his</td>\n",
              "      <td></td>\n",
              "      <td>Charles, Paul, his, his</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>he</td>\n",
              "      <td>Sadiq Khan</td>\n",
              "      <td>True</td>\n",
              "      <td>Gordon Brown</td>\n",
              "      <td>False</td>\n",
              "      <td>the Conservatives, Labour Party, Labour; Sadiq...</td>\n",
              "      <td></td>\n",
              "      <td>he, Sadiq Khan</td>\n",
              "      <td></td>\n",
              "      <td>he, Gordon Brown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>She</td>\n",
              "      <td>Nicole</td>\n",
              "      <td>True</td>\n",
              "      <td>Grace</td>\n",
              "      <td>False</td>\n",
              "      <td>Nicole, her, She, her, she, Nicole, She, her, ...</td>\n",
              "      <td>Nicole, her, She, her, she, Nicole, She, her, ...</td>\n",
              "      <td></td>\n",
              "      <td>Nicole, her, She, her, she, Nicole, She, her, ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>He</td>\n",
              "      <td>Walter Freeman</td>\n",
              "      <td>True</td>\n",
              "      <td>Almansi</td>\n",
              "      <td>False</td>\n",
              "      <td>the Columbus Hospital in New York City, This; ...</td>\n",
              "      <td></td>\n",
              "      <td>He, Walter Freeman</td>\n",
              "      <td></td>\n",
              "      <td>He, Almansi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>her</td>\n",
              "      <td>Mrs Firrell</td>\n",
              "      <td>False</td>\n",
              "      <td>Beryl Agnes Farry</td>\n",
              "      <td>True</td>\n",
              "      <td>the estate, Killarney, its, Killarney, it; Emi...</td>\n",
              "      <td></td>\n",
              "      <td>her, Beryl Agnes Farry</td>\n",
              "      <td></td>\n",
              "      <td>her, Mrs Firrell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>he</td>\n",
              "      <td>Edgar Savisaar</td>\n",
              "      <td>False</td>\n",
              "      <td>Ilves</td>\n",
              "      <td>True</td>\n",
              "      <td>he, Ilves, Edgar Savisaar, Ilves ', he; the Ce...</td>\n",
              "      <td>he, Ilves, Edgar Savisaar, Ilves ', he</td>\n",
              "      <td></td>\n",
              "      <td>he, Ilves, Edgar Savisaar, Ilves ', he</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>her</td>\n",
              "      <td>Queen Mary</td>\n",
              "      <td>False</td>\n",
              "      <td>Elizabeth</td>\n",
              "      <td>True</td>\n",
              "      <td>Bisset, the ship, she, her; the trials, her tr...</td>\n",
              "      <td>Queen Mary, Queen Elizabeth, her, her older si...</td>\n",
              "      <td></td>\n",
              "      <td>Queen Mary, Queen Elizabeth, her, her older si...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>his</td>\n",
              "      <td>Cecil Calvert</td>\n",
              "      <td>False</td>\n",
              "      <td>Duke</td>\n",
              "      <td>True</td>\n",
              "      <td>Cecil Calvert , 2nd Baron Baltimore , Propriet...</td>\n",
              "      <td></td>\n",
              "      <td>his, Duke</td>\n",
              "      <td></td>\n",
              "      <td>his, Cecil Calvert</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>she</td>\n",
              "      <td>Kristy Puchko</td>\n",
              "      <td>True</td>\n",
              "      <td>Daniela Sandiford</td>\n",
              "      <td>False</td>\n",
              "      <td>the film, the film, it, it, the film ' s; the ...</td>\n",
              "      <td></td>\n",
              "      <td>she, Kristy Puchko</td>\n",
              "      <td></td>\n",
              "      <td>she, Daniela Sandiford</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>he</td>\n",
              "      <td>Brian Bosworth</td>\n",
              "      <td>True</td>\n",
              "      <td>Jackson</td>\n",
              "      <td>False</td>\n",
              "      <td>two 2016 Kia Sorento commercials, Both commerc...</td>\n",
              "      <td>the aforementioned Bo Jackson, he, Jackson</td>\n",
              "      <td>he, Brian Bosworth</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>He</td>\n",
              "      <td>Clyde Lovellette</td>\n",
              "      <td>True</td>\n",
              "      <td>Win Wilfong</td>\n",
              "      <td>False</td>\n",
              "      <td>a Helms Foundation National Championship, The ...</td>\n",
              "      <td></td>\n",
              "      <td>He, Clyde Lovellette</td>\n",
              "      <td></td>\n",
              "      <td>He, Win Wilfong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>his</td>\n",
              "      <td>Patrick Bridgwater</td>\n",
              "      <td>True</td>\n",
              "      <td>Schnack</td>\n",
              "      <td>False</td>\n",
              "      <td>His, his, his, Schnack ' s; his most significa...</td>\n",
              "      <td></td>\n",
              "      <td>his, Patrick Bridgwater</td>\n",
              "      <td></td>\n",
              "      <td>his, Schnack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>he</td>\n",
              "      <td>Ricardo Rocha</td>\n",
              "      <td>True</td>\n",
              "      <td>Eugenio Bernal</td>\n",
              "      <td>False</td>\n",
              "      <td>Radi * polis, Radi * polis; The first , journa...</td>\n",
              "      <td></td>\n",
              "      <td>he, Ricardo Rocha</td>\n",
              "      <td></td>\n",
              "      <td>he, Eugenio Bernal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>his</td>\n",
              "      <td>MacDonald</td>\n",
              "      <td>False</td>\n",
              "      <td>Houllier</td>\n",
              "      <td>True</td>\n",
              "      <td>MacDonald, MacDonald, his, MacDonald; Villa, t...</td>\n",
              "      <td>MacDonald, MacDonald, his, MacDonald</td>\n",
              "      <td></td>\n",
              "      <td>former Liverpool and Olympique Lyonnais manage...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>her</td>\n",
              "      <td>Edith Jessie Graydon</td>\n",
              "      <td>True</td>\n",
              "      <td>Ethel Jessie Liles</td>\n",
              "      <td>False</td>\n",
              "      <td>William Eustace Graydon ( 1867 - - 1941 ) , a ...</td>\n",
              "      <td></td>\n",
              "      <td>her, Edith Jessie Graydon</td>\n",
              "      <td></td>\n",
              "      <td>her, Ethel Jessie Liles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>him</td>\n",
              "      <td>Alan</td>\n",
              "      <td>True</td>\n",
              "      <td>Gasazi</td>\n",
              "      <td>False</td>\n",
              "      <td>Gasazi, he, his, his, he, Alan, Gasazi, him, h...</td>\n",
              "      <td>Gasazi, he, his, his, he, Alan, Gasazi, him, him</td>\n",
              "      <td></td>\n",
              "      <td>Gasazi, he, his, his, he, Alan, Gasazi, him, him</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>he</td>\n",
              "      <td>Todd McCarthy</td>\n",
              "      <td>False</td>\n",
              "      <td>Bill Forsyth</td>\n",
              "      <td>True</td>\n",
              "      <td>Gregory ' s Girl, it, the sleeper hit , Gregor...</td>\n",
              "      <td></td>\n",
              "      <td>he, Bill Forsyth</td>\n",
              "      <td></td>\n",
              "      <td>he, Todd McCarthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>his</td>\n",
              "      <td>Ezra</td>\n",
              "      <td>True</td>\n",
              "      <td>Spencer</td>\n",
              "      <td>False</td>\n",
              "      <td>Aria ( Lucy Hale ), Spencer, his, her, Aria, S...</td>\n",
              "      <td>Aria ( Lucy Hale ), Spencer, his, her, Aria, S...</td>\n",
              "      <td>his, Ezra</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>his</td>\n",
              "      <td>Ritchie</td>\n",
              "      <td>False</td>\n",
              "      <td>Franklin D. Roosevelt</td>\n",
              "      <td>True</td>\n",
              "      <td>his, Ritchie, Ritchie; 1933, 1933; Franklin D ...</td>\n",
              "      <td>his, Ritchie, Ritchie</td>\n",
              "      <td>his, Franklin D. Roosevelt</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>his</td>\n",
              "      <td>Rad Hourani</td>\n",
              "      <td>False</td>\n",
              "      <td>Hung Vanngo</td>\n",
              "      <td>True</td>\n",
              "      <td>Her, she; Rad Hourani, Rad Hourani ' s; Rad Ho...</td>\n",
              "      <td></td>\n",
              "      <td>his, Hung Vanngo</td>\n",
              "      <td></td>\n",
              "      <td>his, Rad Hourani</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>she</td>\n",
              "      <td>Diaz-Twine</td>\n",
              "      <td>True</td>\n",
              "      <td>Lillian</td>\n",
              "      <td>False</td>\n",
              "      <td>Diaz - Twine and Jon, them; Lillian, Lillian, ...</td>\n",
              "      <td>Lillian, Lillian, Lillian, she, Lillian</td>\n",
              "      <td>she, Diaz-Twine</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>him</td>\n",
              "      <td>Nolan</td>\n",
              "      <td>False</td>\n",
              "      <td>Sir Trenton</td>\n",
              "      <td>False</td>\n",
              "      <td>Nolan, him, his, he, his, Nolan, him; Stripes ...</td>\n",
              "      <td>Nolan, him, his, he, his, Nolan, him</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>him, Sir Trenton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>his</td>\n",
              "      <td>Jonathan Foyle</td>\n",
              "      <td>True</td>\n",
              "      <td>Ian Burton</td>\n",
              "      <td>False</td>\n",
              "      <td>The presentation team, The team; the architect...</td>\n",
              "      <td></td>\n",
              "      <td>his, Jonathan Foyle</td>\n",
              "      <td></td>\n",
              "      <td>his, Ian Burton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>his</td>\n",
              "      <td>Wilkins</td>\n",
              "      <td>True</td>\n",
              "      <td>Edward Lhuyd</td>\n",
              "      <td>False</td>\n",
              "      <td>The manuscript, it, it, the manuscript; Thomas...</td>\n",
              "      <td></td>\n",
              "      <td>his, Wilkins</td>\n",
              "      <td></td>\n",
              "      <td>his, Edward Lhuyd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>he</td>\n",
              "      <td>John Huntington</td>\n",
              "      <td>True</td>\n",
              "      <td>Ribaldi</td>\n",
              "      <td>False</td>\n",
              "      <td>Ribaldi, he, Ribaldi ' s, Ribaldi; She, She, h...</td>\n",
              "      <td>Ribaldi, he, Ribaldi ' s, Ribaldi</td>\n",
              "      <td>he, John Huntington</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>her</td>\n",
              "      <td>Seema</td>\n",
              "      <td>False</td>\n",
              "      <td>Shalini</td>\n",
              "      <td>False</td>\n",
              "      <td>Shalini, her, Her, she, Seema, Seema, Shalini,...</td>\n",
              "      <td>Shalini, her, Her, she, Seema, Seema, Shalini,...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>his</td>\n",
              "      <td>Charlie Feathers</td>\n",
              "      <td>False</td>\n",
              "      <td>Billy Hancock</td>\n",
              "      <td>True</td>\n",
              "      <td>Their TURKEY MOUNTAIN RECORDS TM Archival Seri...</td>\n",
              "      <td></td>\n",
              "      <td>his, Billy Hancock</td>\n",
              "      <td></td>\n",
              "      <td>his, Charlie Feathers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pronoun  ...                   str_tn\n",
              "4      she  ...        she, Finch Hatton\n",
              "5       he  ...          he, James Randi\n",
              "7      his  ...               his, Colin\n",
              "8       he  ...                         \n",
              "9      her  ...                         \n",
              "10      he  ...     he, Ioannis Mamouris\n",
              "12     her  ...             her, Crystal\n",
              "13     his  ...          his, Dan Dailey\n",
              "18     his  ...                         \n",
              "19     his  ...              his, Morris\n",
              "20     his  ...           his, Joe Brown\n",
              "24     his  ...              his, Adkins\n",
              "25     his  ...              his, Mughal\n",
              "28     him  ...                         \n",
              "30      He  ...              He, Baronet\n",
              "32     his  ...              his, Nelson\n",
              "36      He  ...     He, Ahmad bin Marwan\n",
              "37      he  ...          he, Daniel Sims\n",
              "38     his  ...       his, Lobsang Rampa\n",
              "39     his  ...                         \n",
              "41      he  ...         he, Gordon Brown\n",
              "42     She  ...                         \n",
              "43      He  ...              He, Almansi\n",
              "44     her  ...         her, Mrs Firrell\n",
              "45      he  ...                         \n",
              "48     her  ...                         \n",
              "51     his  ...       his, Cecil Calvert\n",
              "54     she  ...   she, Daniela Sandiford\n",
              "55      he  ...                         \n",
              "56      He  ...          He, Win Wilfong\n",
              "58     his  ...             his, Schnack\n",
              "59      he  ...       he, Eugenio Bernal\n",
              "62     his  ...                         \n",
              "64     her  ...  her, Ethel Jessie Liles\n",
              "65     him  ...                         \n",
              "66      he  ...        he, Todd McCarthy\n",
              "67     his  ...                         \n",
              "76     his  ...                         \n",
              "77     his  ...         his, Rad Hourani\n",
              "79     she  ...                         \n",
              "82     him  ...         him, Sir Trenton\n",
              "83     his  ...          his, Ian Burton\n",
              "85     his  ...        his, Edward Lhuyd\n",
              "89      he  ...                         \n",
              "96     her  ...                         \n",
              "99     his  ...    his, Charlie Feathers\n",
              "\n",
              "[46 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXHI0yo-5SSz"
      },
      "source": [
        "def make_pos_neg(a, a_value, b, b_value):\r\n",
        "    positives = []\r\n",
        "    negatives = []\r\n",
        "    if a_value:\r\n",
        "        positives.append(a)\r\n",
        "    else:\r\n",
        "        negatives.append(a)\r\n",
        "\r\n",
        "    if b_value:\r\n",
        "        positives.append(b)\r\n",
        "    else:\r\n",
        "        negatives.append(b)\r\n",
        "\r\n",
        "    return ', '.join(positives), ', '.join(negatives)"
      ],
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs-7TH8CA09X"
      },
      "source": [
        "p_n = test_df.apply(lambda x: make_pos_neg(x['A'], x['A-coref'], x['B'], x['B-coref']), axis=1).values"
      ],
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "4mMmfdcZA8jl",
        "outputId": "732b4fa9-af9e-434b-a17e-834932b062ac"
      },
      "source": [
        "test_df['positives'] = [x[0] for x in p_n]\r\n",
        "test_df['negatives'] = [x[1] for x in p_n]\r\n",
        "test_df.head()"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Pronoun</th>\n",
              "      <th>Pronoun-offset</th>\n",
              "      <th>A</th>\n",
              "      <th>A-offset</th>\n",
              "      <th>A-coref</th>\n",
              "      <th>B</th>\n",
              "      <th>B-offset</th>\n",
              "      <th>B-coref</th>\n",
              "      <th>URL</th>\n",
              "      <th>sentences</th>\n",
              "      <th>len</th>\n",
              "      <th>clusters</th>\n",
              "      <th>tp</th>\n",
              "      <th>tp_count</th>\n",
              "      <th>str_tp</th>\n",
              "      <th>fp</th>\n",
              "      <th>fp_count</th>\n",
              "      <th>str_fp</th>\n",
              "      <th>tn</th>\n",
              "      <th>tn_count</th>\n",
              "      <th>str_tn</th>\n",
              "      <th>fn</th>\n",
              "      <th>fn_count</th>\n",
              "      <th>str_fn</th>\n",
              "      <th>str_clusters</th>\n",
              "      <th>positives</th>\n",
              "      <th>negatives</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>validation-1</td>\n",
              "      <td>He admitted making four trips to China and pla...</td>\n",
              "      <td>him</td>\n",
              "      <td>256</td>\n",
              "      <td>Jose de Venecia Jr</td>\n",
              "      <td>208</td>\n",
              "      <td>False</td>\n",
              "      <td>Abalos</td>\n",
              "      <td>241</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Commission_on_Ele...</td>\n",
              "      <td>[He admitted making four trips to China and pl...</td>\n",
              "      <td>3</td>\n",
              "      <td>[[He, He, he, his], [four trips to China, the ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>[[him, Jose de Venecia Jr], [him, Abalos]]</td>\n",
              "      <td>2</td>\n",
              "      <td>him, Jose de Venecia Jr; him, Abalos</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>He, He, he, his; four trips to China, the trip...</td>\n",
              "      <td></td>\n",
              "      <td>Jose de Venecia Jr, Abalos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>validation-2</td>\n",
              "      <td>Kathleen Nott was born in Camberwell, London. ...</td>\n",
              "      <td>She</td>\n",
              "      <td>185</td>\n",
              "      <td>Ellen</td>\n",
              "      <td>110</td>\n",
              "      <td>False</td>\n",
              "      <td>Kathleen</td>\n",
              "      <td>150</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Kathleen_Nott</td>\n",
              "      <td>[Kathleen Nott was born in Camberwell, London....</td>\n",
              "      <td>3</td>\n",
              "      <td>[[Kathleen Nott, Her, her, Kathleen, She], [Lo...</td>\n",
              "      <td>[[Kathleen Nott, Her, her, Kathleen, She]]</td>\n",
              "      <td>1</td>\n",
              "      <td>Kathleen Nott, Her, her, Kathleen, She</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>[[She, Ellen]]</td>\n",
              "      <td>1</td>\n",
              "      <td>She, Ellen</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>Kathleen Nott, Her, her, Kathleen, She; London...</td>\n",
              "      <td>Kathleen</td>\n",
              "      <td>Ellen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>validation-3</td>\n",
              "      <td>When she returns to her hotel room, a Liberian...</td>\n",
              "      <td>his</td>\n",
              "      <td>435</td>\n",
              "      <td>Jason Scott Lee</td>\n",
              "      <td>383</td>\n",
              "      <td>False</td>\n",
              "      <td>Danny</td>\n",
              "      <td>406</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Hawaii_Five-0_(20...</td>\n",
              "      <td>[When she returns to her hotel room, a Liberia...</td>\n",
              "      <td>3</td>\n",
              "      <td>[[she, her, her, She, she, Angela], [the fligh...</td>\n",
              "      <td>[[Danny, his]]</td>\n",
              "      <td>1</td>\n",
              "      <td>Danny, his</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>[[his, Jason Scott Lee]]</td>\n",
              "      <td>1</td>\n",
              "      <td>his, Jason Scott Lee</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>she, her, her, She, she, Angela; the flight, t...</td>\n",
              "      <td>Danny</td>\n",
              "      <td>Jason Scott Lee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>validation-4</td>\n",
              "      <td>On 19 March 2007, during a campaign appearance...</td>\n",
              "      <td>he</td>\n",
              "      <td>333</td>\n",
              "      <td>Reucassel</td>\n",
              "      <td>300</td>\n",
              "      <td>True</td>\n",
              "      <td>Debnam</td>\n",
              "      <td>325</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Craig_Reucassel</td>\n",
              "      <td>[On 19 March 2007, during a campaign appearanc...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[the then opposition leader Peter Debnam, Deb...</td>\n",
              "      <td>[[the then opposition leader Peter Debnam, Deb...</td>\n",
              "      <td>1</td>\n",
              "      <td>the then opposition leader Peter Debnam, Debna...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>[[he, Debnam]]</td>\n",
              "      <td>1</td>\n",
              "      <td>he, Debnam</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>the then opposition leader Peter Debnam, Debna...</td>\n",
              "      <td>Reucassel</td>\n",
              "      <td>Debnam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>validation-5</td>\n",
              "      <td>By this time, Karen Blixen had separated from ...</td>\n",
              "      <td>she</td>\n",
              "      <td>427</td>\n",
              "      <td>Finch Hatton</td>\n",
              "      <td>290</td>\n",
              "      <td>False</td>\n",
              "      <td>Beryl Markham</td>\n",
              "      <td>328</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Denys_Finch_Hatton</td>\n",
              "      <td>[By this time, Karen Blixen had separated from...</td>\n",
              "      <td>4</td>\n",
              "      <td>[[Karen Blixen, her, her], [her husband, Finch...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>[[she, Finch Hatton]]</td>\n",
              "      <td>1</td>\n",
              "      <td>she, Finch Hatton</td>\n",
              "      <td>[[she, Beryl Markham]]</td>\n",
              "      <td>1</td>\n",
              "      <td>she, Beryl Markham</td>\n",
              "      <td>Karen Blixen, her, her; her husband, Finch Hat...</td>\n",
              "      <td>Beryl Markham</td>\n",
              "      <td>Finch Hatton</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             ID  ...                   negatives\n",
              "0  validation-1  ...  Jose de Venecia Jr, Abalos\n",
              "1  validation-2  ...                       Ellen\n",
              "2  validation-3  ...             Jason Scott Lee\n",
              "3  validation-4  ...                      Debnam\n",
              "4  validation-5  ...                Finch Hatton\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oJHtxXOxAyC"
      },
      "source": [
        "export = ['Text', 'Pronoun', 'A', 'A-coref', 'B', 'B-coref',\r\n",
        "          'positives', 'negatives',\r\n",
        "          'str_clusters', 'str_fp', 'str_fn', 'str_tp', 'str_tn',\r\n",
        "          'tp_count', 'fp_count', 'tn_count', 'fn_count']\r\n",
        "export_df = test_df[export]\r\n",
        "export_df.to_csv('results2.tsv', sep='\\t')"
      ],
      "execution_count": 284,
      "outputs": []
    }
  ]
}